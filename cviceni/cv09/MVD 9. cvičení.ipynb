{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MVD 9. cvičení\n\n## 1. část - Seznámení s HuggingFace a modelem BERT\n\nNainstalujte si Python knihovnu `transformers` a podívejte se na předtrénovaný [BERT model](https://huggingface.co/bert-base-uncased). Vyzkoušejte si unmasker s různými vstupy.\n\n<br>\nPozn.: Použití BERT modelu vyžaduje zároveň PyTorch - postačí i cpu verze.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nunmasker = pipeline('fill-mask', model='bert-base-uncased')\nunmasker(\"Hello I'm a [MASK] model.\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:35:48.737848Z","iopub.execute_input":"2021-12-08T20:35:48.738498Z","iopub.status.idle":"2021-12-08T20:35:54.695474Z","shell.execute_reply.started":"2021-12-08T20:35:48.738446Z","shell.execute_reply":"2021-12-08T20:35:54.694566Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[{'sequence': \"hello i'm a fashion model.\",\n  'score': 0.10731059312820435,\n  'token': 4827,\n  'token_str': 'fashion'},\n {'sequence': \"hello i'm a role model.\",\n  'score': 0.08774515986442566,\n  'token': 2535,\n  'token_str': 'role'},\n {'sequence': \"hello i'm a new model.\",\n  'score': 0.05338393896818161,\n  'token': 2047,\n  'token_str': 'new'},\n {'sequence': \"hello i'm a super model.\",\n  'score': 0.04667220264673233,\n  'token': 3565,\n  'token_str': 'super'},\n {'sequence': \"hello i'm a fine model.\",\n  'score': 0.027095947414636612,\n  'token': 2986,\n  'token_str': 'fine'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. část - BERT contextualized word embeddings\n\nBERT dokumentace obsahuje také návod jak použít tento model pro získání word embeddingů. Vyzkoušejte použití stejného slova v různém kontextu a podívejte se, jak se mění kosinova podobnost embeddingů v závislosti na kontextu daného slova.\n\nPodívejte se na výstup tokenizeru před vstupem do BERT modelu - kolik tokenů bylo vytvořeno pro větu \"Hello, this is Bert.\"? Zdůvodněte jejich počet.\n\n<br>\nPozn.: Vyřešení předchozí otázky Vám pomůže zjistit, který vektor z výstupu pro cílové slovo použít.","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\n\ntokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n\ntokens=tokenizer.tokenize(\"Hello, this is Bert.\")\nprint(tokens)\nprint(type(tokens))","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:35:54.697155Z","iopub.execute_input":"2021-12-08T20:35:54.697918Z","iopub.status.idle":"2021-12-08T20:35:57.141288Z","shell.execute_reply.started":"2021-12-08T20:35:54.697881Z","shell.execute_reply":"2021-12-08T20:35:57.140282Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"['hello', ',', 'this', 'is', 'bert', '.']\n<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ndef sentence_to_vectors(sentence):\n    tokens=tokenizer.tokenize(sentence)\n    word_ids = tokenizer.convert_tokens_to_ids(tokens)\n    segments_ids = [1] * len(tokens)\n    tokens_tensor = torch.tensor([word_ids])\n    segments_tensor = torch.tensor([segments_ids])\n\n    model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n    model.eval()\n\n    with torch.no_grad():\n        outputs = model(tokens_tensor, segments_tensor)\n        hidden = outputs[2]\n    \n    token_embeddings = torch.squeeze(torch.stack(hidden, dim=0), dim=1).permute(1,0,2)\n\n    token_vecs_cat = []\n    for token in token_embeddings:\n        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n        token_vecs_cat.append(cat_vec)\n        \n    return token_vecs_cat, tokens","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:35:57.142493Z","iopub.execute_input":"2021-12-08T20:35:57.142820Z","iopub.status.idle":"2021-12-08T20:35:57.152063Z","shell.execute_reply.started":"2021-12-08T20:35:57.142785Z","shell.execute_reply":"2021-12-08T20:35:57.151116Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"sentence_1 = '[CLS] I bought an iPhone in an Apple store. [SEP]'\nsentence_2 = '[CLS] The apple was delicious. [SEP]'","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:35:57.153954Z","iopub.execute_input":"2021-12-08T20:35:57.154191Z","iopub.status.idle":"2021-12-08T20:35:57.164733Z","shell.execute_reply.started":"2021-12-08T20:35:57.154163Z","shell.execute_reply":"2021-12-08T20:35:57.163971Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"embeddings_1, tokens_1 = sentence_to_vectors(sentence_1)\nembeddings_2, tokens_2 = sentence_to_vectors(sentence_2)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:35:57.166192Z","iopub.execute_input":"2021-12-08T20:35:57.166466Z","iopub.status.idle":"2021-12-08T20:36:01.407135Z","shell.execute_reply.started":"2021-12-08T20:35:57.166436Z","shell.execute_reply":"2021-12-08T20:36:01.406097Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"apple_1_vec = embeddings_1[7]\napple_2_vec = embeddings_2[2]\n\nall(apple_1_vec == apple_2_vec), f'L2 difference: {torch.sqrt(torch.sum((apple_1_vec - apple_2_vec)**2))}'","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:36:01.408588Z","iopub.execute_input":"2021-12-08T20:36:01.408942Z","iopub.status.idle":"2021-12-08T20:36:01.422447Z","shell.execute_reply.started":"2021-12-08T20:36:01.408893Z","shell.execute_reply":"2021-12-08T20:36:01.421340Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(False, 'L2 difference: 34.4416389465332')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Bonus - Vizualizace slovních  embeddingů\n\nVizualizujte slovní embeddingy - mění se jejich pozice v závislosti na kontextu tak, jak byste očekávali? Pokuste se vizualizovat i některá slova, ke kterým by se podle vás cílové slovo mělo po změně kontextu přiblížit.","metadata":{}},{"cell_type":"code","source":"!pip install MulticoreTSNE\n\nfrom MulticoreTSNE import MulticoreTSNE as TSNE\nimport plotly.graph_objects as go\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:36:01.423623Z","iopub.execute_input":"2021-12-08T20:36:01.424084Z","iopub.status.idle":"2021-12-08T20:36:10.053544Z","shell.execute_reply.started":"2021-12-08T20:36:01.424037Z","shell.execute_reply":"2021-12-08T20:36:10.052449Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: MulticoreTSNE in /opt/conda/lib/python3.7/site-packages (0.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from MulticoreTSNE) (1.19.5)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from MulticoreTSNE) (1.15.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->MulticoreTSNE) (2.21)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def embeddings_to_numpy(embeddings):\n    return np.array([t.numpy() for t in embeddings])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:36:10.056482Z","iopub.execute_input":"2021-12-08T20:36:10.056857Z","iopub.status.idle":"2021-12-08T20:36:10.062084Z","shell.execute_reply.started":"2021-12-08T20:36:10.056812Z","shell.execute_reply":"2021-12-08T20:36:10.061143Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = TSNE(n_components=3, perplexity=3, verbose=1, n_jobs=12)\nX_new = model.fit_transform(embeddings_to_numpy(embeddings_1 + embeddings_2))\nx = X_new[:, 0]\ny = X_new[:, 1]\nz = X_new[:, 2]","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:37:23.000663Z","iopub.execute_input":"2021-12-08T20:37:23.000954Z","iopub.status.idle":"2021-12-08T20:37:23.183323Z","shell.execute_reply.started":"2021-12-08T20:37:23.000925Z","shell.execute_reply":"2021-12-08T20:37:23.182673Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Performing t-SNE using 12 cores.\nUsing no_dims = 3, perplexity = 3.000000, and theta = 0.500000\nComputing input similarities...\nBuilding tree...\n - point 1 of 18\n - point 9 of 18\n - point 10 of 18\n - point 11 of 18\n - point 12 of 18\n - point 12 of 18\n - point 13 of 18\n - point 14 of 18\n - point 14 of 18\n - point 14 of 18\n - point 15 of 18\n - point 16 of 18\n - point 16 of 18\n - point 17 of 18\n - point 17 of 18\n - point 17 of 18\n - point 18 of 18\n - point 18 of 18\nDone in 0.00 seconds (sparsity = 0.592593)!\nLearning embedding...\nIteration 51: error is 46.277876 (50 iterations in 0.00 seconds)\nIteration 101: error is 53.287013 (50 iterations in 0.00 seconds)\nIteration 151: error is 56.311864 (50 iterations in 0.00 seconds)\nIteration 201: error is 53.174553 (50 iterations in 0.00 seconds)\nIteration 251: error is 62.750171 (50 iterations in 0.00 seconds)\nIteration 301: error is 1.815296 (50 iterations in 0.00 seconds)\nIteration 351: error is 0.748303 (50 iterations in 0.00 seconds)\nIteration 401: error is 0.211869 (50 iterations in 0.00 seconds)\nIteration 451: error is 0.164029 (50 iterations in 0.00 seconds)\nIteration 501: error is 0.155022 (50 iterations in 0.00 seconds)\nIteration 551: error is 0.153374 (50 iterations in 0.00 seconds)\nIteration 601: error is 0.151488 (50 iterations in 0.00 seconds)\nIteration 651: error is 0.150320 (50 iterations in 0.00 seconds)\nIteration 701: error is 0.150497 (50 iterations in 0.00 seconds)\nIteration 751: error is 0.149472 (50 iterations in 0.00 seconds)\nIteration 801: error is 0.148698 (50 iterations in 0.00 seconds)\nIteration 851: error is 0.147057 (50 iterations in 0.00 seconds)\nIteration 901: error is 0.144563 (50 iterations in 0.00 seconds)\nIteration 951: error is 0.142554 (50 iterations in 0.00 seconds)\nIteration 1000: error is 0.144029 (50 iterations in 0.00 seconds)\nFitting performed in 0.00 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"fig = go.Figure(\n    data=[\n        go.Scatter3d(\n            x=x,\n            y=y,\n            z=z,\n            text=tokens_1 + tokens_2,\n            mode='markers',\n            marker=dict(\n                size=12,\n                color=z,\n                colorscale='Viridis',\n                opacity=0.7,\n            ),\n        ),\n    ],\n)\n\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T20:37:24.801697Z","iopub.execute_input":"2021-12-08T20:37:24.801994Z","iopub.status.idle":"2021-12-08T20:37:24.819729Z","shell.execute_reply.started":"2021-12-08T20:37:24.801964Z","shell.execute_reply":"2021-12-08T20:37:24.819067Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"9c26ca6c-b7c8-4869-b6ae-516cceca7a6e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c26ca6c-b7c8-4869-b6ae-516cceca7a6e\")) {                    Plotly.newPlot(                        \"9c26ca6c-b7c8-4869-b6ae-516cceca7a6e\",                        [{\"marker\":{\"color\":[30.670151762183245,69.0460841886627,82.28911340253154,88.79104163917515,23.072709332762063,133.8040226589749,115.21710428856184,4.431747246618471,108.90758574280179,32.98851741255389,-7.7101678977490975,18.31629991498644,-173.1700642529862,-151.62318639460136,-194.14369266296418,-180.15563675441663,10.99861110972596,-11.730240736820372],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"opacity\":0.7,\"size\":12},\"mode\":\"markers\",\"text\":[\"[CLS]\",\"i\",\"bought\",\"an\",\"iphone\",\"in\",\"an\",\"apple\",\"store\",\".\",\"[SEP]\",\"[CLS]\",\"the\",\"apple\",\"was\",\"delicious\",\".\",\"[SEP]\"],\"x\":[-55.647862541100885,-0.6081473872912437,21.223221891408155,41.090705174036835,102.1199483634366,60.10680961394532,48.59420985618318,108.1338611415124,22.238503032667246,-44.716183422921866,-57.73272780278148,-69.93644991868503,-23.434942272463104,5.7036251499866655,-23.459761291575422,-7.248475709658645,-55.65343522249444,-70.77289865420433],\"y\":[4.048932394123337,17.52959627577639,33.43678946846735,37.780271650888714,31.356389704868707,61.16038868786622,57.244551319724806,29.699945009878846,76.7061310573518,-57.33476858912618,-99.90148064430724,7.274457399253968,-21.6431797493813,-3.2887077138630048,-10.758402090188138,-1.3358919130568023,-77.0560031808656,-84.9190190874119],\"z\":[30.670151762183245,69.0460841886627,82.28911340253154,88.79104163917515,23.072709332762063,133.8040226589749,115.21710428856184,4.431747246618471,108.90758574280179,32.98851741255389,-7.7101678977490975,18.31629991498644,-173.1700642529862,-151.62318639460136,-194.14369266296418,-180.15563675441663,10.99861110972596,-11.730240736820372],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"margin\":{\"l\":0,\"r\":0,\"b\":0,\"t\":0}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('9c26ca6c-b7c8-4869-b6ae-516cceca7a6e');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]}]}