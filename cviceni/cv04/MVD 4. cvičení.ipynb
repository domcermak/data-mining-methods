{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MVD 4. cvičení\n",
    "\n",
    "## 1. část - Načtení dat\n",
    "\n",
    "Po rozbalení archive.zip uvidíte articles csv soubor. Tento soubor pochází z [Kaggle datasetů](https://www.kaggle.com/hsankesara/medium-articles) a obsahuje malé množství Medium článků k tématům ML, AI a data science. K úloze dnešního cvičení bude stačit využítí dat s názvy a obsahy článků (title a text).\n",
    "\n",
    "\n",
    "### Příprava dat\n",
    "\n",
    "Pro přípravu dat se použivá různá sekvence kroků. Je doporučeno na následující kroky vytvořit samostatnou funkci, aby bylo možné zpracovat i vyhledávaný výraz při testování. Dnešní cvičení by mělo obsahovat následující kroky:\n",
    "\n",
    "1. Převést všechen text na lower case\n",
    "2. Odstranění interpunkce a všech speciálních znaků (apostrof, ...)\n",
    "3. Aplikace lemmatizátoru\n",
    "\n",
    "Pozn.: Jedná se pouze o jednoduchý preprocessing, v praxi je často potřeba použití více kroků. Tato aplikace by měla například problém s čísly (desetinná čísla, čísla vyhledávaná slovně). \n",
    "\n",
    "Pro lemmatizaci použijte knihovnu spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (2.3.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (0.7.4)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (2.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (1.1.0)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (4.62.3)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (7.4.5)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (1.0.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (58.0.4)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (3.0.5)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (2.26.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (1.21.2)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy) (0.8.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\r\n",
      "Collecting en_core_web_sm==2.3.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 12.0 MB 6.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.26.0)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.62.3)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\r\n",
      "Requirement already satisfied: setuptools in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (58.0.4)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.21.2)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.10.0.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.6.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.7)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.10.8)\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the model via spacy.load('en_core_web_sm')\r\n",
      "\u001B[38;5;2m✔ Linking successful\u001B[0m\r\n",
      "/Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages/en_core_web_sm\r\n",
      "-->\r\n",
      "/Users/admin/opt/anaconda3/envs/MVD_2021/lib/python3.7/site-packages/spacy/data/en\r\n",
      "You can now load the model via spacy.load('en')\r\n"
     ]
    }
   ],
   "source": [
    "# Instalace spaCy z Jupyter Notebooku\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "!{sys.executable} -m pip install spacy\n",
    "\n",
    "# Stažení modelu pro angličtinu\n",
    "!{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "# Lemmatizace textu př.:\n",
    "# \" \".join([token.lemma_ for token in lemmatizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>Want to learn about applied Artificial Intelli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author claps  reading_time  \\\n",
       "0        Justin Lee  8.3K            11   \n",
       "1       Conor Dewey  1.4K             7   \n",
       "2  William Koehrsen  2.8K            11   \n",
       "3      Gant Laborde  1.3K             7   \n",
       "4  Emmanuel Ameisen   935            11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://medium.freecodecamp.org/machine-learni...   \n",
       "4  https://blog.insightdatascience.com/reinforcem...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "1  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2  Automated Feature Engineering in Python – Towa...   \n",
       "3  Machine Learning: how to go from Zero to Hero ...   \n",
       "4  Reinforcement Learning from scratch – Insight ...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1  If you’ve ever found yourself looking up the s...  \n",
       "2  Machine learning is increasingly moving from h...  \n",
       "3  If your understanding of A.I. and Machine Lear...  \n",
       "4  Want to learn about applied Artificial Intelli...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('articles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def lower(s: str) -> str:\n",
    "    return s.lower()\n",
    "\n",
    "def strip_punctuation(s: str) -> str:\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def lemmanize(s: str) -> str:\n",
    "    return ' '.join([token.lemma_ for token in lemmatizer(s)])\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> None:\n",
    "    for column in ['author', 'title', 'text', 'claps']:\n",
    "        df[column] = df[column].apply(lower).apply(strip_punctuation).apply(lemmanize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>justin lee</td>\n",
       "      <td>83k</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>chatbot be the next big thing what happen – th...</td>\n",
       "      <td>oh how the headline blare \\n chatbot be the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conor dewey</td>\n",
       "      <td>14k</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>python for data science 8 concept -PRON- may h...</td>\n",
       "      <td>if -PRON- have ever find -PRON- look up the sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>william koehrsen</td>\n",
       "      <td>28k</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>automate feature engineering in python – towar...</td>\n",
       "      <td>machine learning be increasingly move from han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gant laborde</td>\n",
       "      <td>13k</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>machine learn how to go from zero to hero – fr...</td>\n",
       "      <td>if -PRON- understanding of ai and machine lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emmanuel ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>reinforcement learn from scratch – insight datum</td>\n",
       "      <td>want to learn about applied artificial intelli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author claps  reading_time  \\\n",
       "0        justin lee   83k            11   \n",
       "1       conor dewey   14k             7   \n",
       "2  william koehrsen   28k            11   \n",
       "3      gant laborde   13k             7   \n",
       "4  emmanuel ameisen   935            11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://medium.freecodecamp.org/machine-learni...   \n",
       "4  https://blog.insightdatascience.com/reinforcem...   \n",
       "\n",
       "                                               title  \\\n",
       "0  chatbot be the next big thing what happen – th...   \n",
       "1  python for data science 8 concept -PRON- may h...   \n",
       "2  automate feature engineering in python – towar...   \n",
       "3  machine learn how to go from zero to hero – fr...   \n",
       "4   reinforcement learn from scratch – insight datum   \n",
       "\n",
       "                                                text  \n",
       "0  oh how the headline blare \\n chatbot be the ne...  \n",
       "1  if -PRON- have ever find -PRON- look up the sa...  \n",
       "2  machine learning be increasingly move from han...  \n",
       "3  if -PRON- understanding of ai and machine lear...  \n",
       "4  want to learn about applied artificial intelli...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. část - Vytvoření invertovaného indexu\n",
    "\n",
    "Před další prací s textem je potřeba vytvořit invertovaný index, který poté usnadní práci. Invertovaný index bude slovník, kde klíčem bude slovo a hodnotou bude list s id dokumentů (index), které dané slovo obsahují.\n",
    "\n",
    "Pozn.: Je potřeba vytvořit dva invertované indexy - jeden pro title a druhý pro text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_index(data):\n",
    "    word_to_idx = {}\n",
    "    for idx, title in enumerate(data):\n",
    "        for word in title.split():\n",
    "            if not word in word_to_idx:\n",
    "                word_to_idx[word] = {idx}\n",
    "            else:\n",
    "                word_to_idx[word].add(idx)\n",
    "\n",
    "    return word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_word_to_idx = make_index(df.title)\n",
    "text_word_to_idx = make_index(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chatbot': {0, 86, 96, 192, 223, 257, 267, 273},\n",
       " 'be': {0,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  18,\n",
       "  36,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  61,\n",
       "  83,\n",
       "  86,\n",
       "  87,\n",
       "  98,\n",
       "  108,\n",
       "  113,\n",
       "  121,\n",
       "  123,\n",
       "  128,\n",
       "  136,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  153,\n",
       "  169,\n",
       "  170,\n",
       "  216,\n",
       "  218,\n",
       "  224,\n",
       "  227,\n",
       "  231,\n",
       "  233,\n",
       "  237,\n",
       "  243,\n",
       "  246,\n",
       "  258,\n",
       "  261,\n",
       "  264,\n",
       "  267,\n",
       "  273,\n",
       "  321,\n",
       "  330,\n",
       "  335}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(title_word_to_idx.items())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. část - Implementace TF-IDF\n",
    "\n",
    "Připravení funkce pro výpočet TF-IDF po příchodu dotazu. Funkce *tf_idf* by měla pracovat s dotazem, jedním invertovaným indexem a s danými dokumenty. Vrátit by měla list obsahující skóre pro každý dokument.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "$\n",
    "score(q,d) = TF\\_IDF(q,d) = \\sum\\limits_{w \\in q \\cap d} c(w, q) c(w, d) log(\\frac{M+1}{df(w)})\n",
    "$\n",
    "</center>\n",
    "\n",
    "$q$ ... dotaz<br>\n",
    "$d$ ... dokument<br>\n",
    "$c(w, q)$ ... kolikrát je slovo *w* v dotazu *q*<br>\n",
    "$M$ ... celkový počet dokumentů<br>\n",
    "$df(w)$ ... počet dokumentů, ve kterých se nachází slovo *w*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(query, document, num_docs, word_to_idx):\n",
    "    normalized_query = lemmanize(strip_punctuation(lower(query))).strip()\n",
    "    words_in_query = normalized_query.split()\n",
    "\n",
    "    score = 0\n",
    "    for word_in_query in set(words_in_query):\n",
    "        if not word_in_query in word_to_idx:\n",
    "            continue\n",
    "\n",
    "        num_document_occurrences = document.count(word_in_query) # c(w, d)\n",
    "        if num_document_occurrences == 0:\n",
    "            continue\n",
    "\n",
    "        num_query_occurrences = words_in_query.count(word_in_query) # c(w, q)\n",
    "        num_word_in_documents = len(word_to_idx[word_in_query]) # df\n",
    "\n",
    "        score += num_query_occurrences * num_document_occurrences * np.log((num_docs + 1) / num_word_in_documents)\n",
    "\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. část - Použití a testování TF-IDF\n",
    "\n",
    "Nyní lze získat skóre pro titulky nebo text. Následujícím krokem je sjednocení výsledného skóre pro ohodnocení celého dokumentu. V případě dvou hodnot si vystačíme s parametrem $\\alpha$, který nám určuje jakou váhu má titulek a jakou samotný text dokumentu. <br>\n",
    "\n",
    "<center>\n",
    "$\n",
    "score(q,d) = \\alpha \\; TF\\_IDF\\_title(q,d) + (1-\\alpha) \\; TF\\_IDF\\_text(q,d)\n",
    "$\n",
    "</center>\n",
    "\n",
    "Při nastavení parametru $\\alpha$ na hodnotu 0.7 a vyhledávání dotazu \"coursera vs udacity machine learning\" by výsledky měly vypadat následovně:\n",
    "\n",
    "![output](sample_output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_score(titles, texts, title_word_to_idx, text_word_to_idx, alpha, query):\n",
    "    assert len(titles) == len(texts)\n",
    "\n",
    "    num_documents = len(titles)\n",
    "    scores = np.zeros((num_documents, 1))\n",
    "\n",
    "    for i in range(num_documents):\n",
    "        title, text = titles[i], texts[i]\n",
    "        scores[i] = alpha * tf_idf(query, title, num_documents, title_word_to_idx) + \\\n",
    "                (1 - alpha) * tf_idf(query, text, num_documents, text_word_to_idx)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['score'] = make_score(query='coursera vs udacity machine learning',\n",
    "           titles=df.title,\n",
    "           texts=df.text,\n",
    "           title_word_to_idx=title_word_to_idx,\n",
    "           text_word_to_idx=text_word_to_idx,\n",
    "           alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>coursera vs udacity for machine learning – hac...</td>\n",
       "      <td>2018 be an exciting time for student of machin...</td>\n",
       "      <td>42.880391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>every single machine learn course on the inter...</td>\n",
       "      <td>a year and a half ago i drop out of one of the...</td>\n",
       "      <td>34.781632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>every single machine learn course on the inter...</td>\n",
       "      <td>a year and a half ago i drop out of one of the...</td>\n",
       "      <td>34.781632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>every single machine learn course on the inter...</td>\n",
       "      <td>a year and a half ago i drop out of one of the...</td>\n",
       "      <td>34.781632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>every single machine learn course on the inter...</td>\n",
       "      <td>a year and a half ago i drop out of one of the...</td>\n",
       "      <td>34.781632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>machine learn in a week – learn new stuff – me...</td>\n",
       "      <td>get into machine learning ml can seem like an ...</td>\n",
       "      <td>11.244242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>in defense of skepticism about deep learning –...</td>\n",
       "      <td>in a recent appraisal of deep learning marcus ...</td>\n",
       "      <td>9.346694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>in defense of skepticism about deep learning –...</td>\n",
       "      <td>in a recent appraisal of deep learning marcus ...</td>\n",
       "      <td>9.346694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>machine learn in a year – learn new stuff – me...</td>\n",
       "      <td>this be a follow up to an article i write last...</td>\n",
       "      <td>9.321382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>machine learning be fun – adam geitgey – medium</td>\n",
       "      <td>update this article be part of a series check ...</td>\n",
       "      <td>8.150912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "276  coursera vs udacity for machine learning – hac...   \n",
       "143  every single machine learn course on the inter...   \n",
       "67   every single machine learn course on the inter...   \n",
       "99   every single machine learn course on the inter...   \n",
       "19   every single machine learn course on the inter...   \n",
       "47   machine learn in a week – learn new stuff – me...   \n",
       "327  in defense of skepticism about deep learning –...   \n",
       "209  in defense of skepticism about deep learning –...   \n",
       "64   machine learn in a year – learn new stuff – me...   \n",
       "36     machine learning be fun – adam geitgey – medium   \n",
       "\n",
       "                                                  text      score  \n",
       "276  2018 be an exciting time for student of machin...  42.880391  \n",
       "143  a year and a half ago i drop out of one of the...  34.781632  \n",
       "67   a year and a half ago i drop out of one of the...  34.781632  \n",
       "99   a year and a half ago i drop out of one of the...  34.781632  \n",
       "19   a year and a half ago i drop out of one of the...  34.781632  \n",
       "47   get into machine learning ml can seem like an ...  11.244242  \n",
       "327  in a recent appraisal of deep learning marcus ...   9.346694  \n",
       "209  in a recent appraisal of deep learning marcus ...   9.346694  \n",
       "64   this be a follow up to an article i write last...   9.321382  \n",
       "36   update this article be part of a series check ...   8.150912  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='score', ascending=False).head(10)[['title', 'text', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}